{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b486752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affa60d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper metric functions\n",
    "\n",
    "def roc_auc(actual, preds):\n",
    "    \"\"\"Manual ROC-AUC implementation copied from metrics.ipynb.\"\"\"\n",
    "    actual = np.array(actual) == 1\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for thresh in [x / 100.0 for x in range(0, 101)]:\n",
    "        preds_t = np.array(preds) >= thresh\n",
    "        tp = sum(preds_t & actual)\n",
    "        fp = sum(preds_t & ~actual)\n",
    "        tn = sum(~preds_t & ~actual)\n",
    "        fn = sum(~preds_t & actual)\n",
    "        tpr.append(tp / (tp + fn))\n",
    "        fpr.append(tn / (tn + fp))\n",
    "\n",
    "    auc = 0\n",
    "    for i in range(0, len(tpr) - 1):\n",
    "        auc += ((tpr[i] + tpr[i + 1]) / 2) * (fpr[i + 1] - fpr[i])\n",
    "    return auc\n",
    "\n",
    "\n",
    "def accuracy(actual, preds, thresh):\n",
    "    # pred should be a list of predicted probabilities between 0 and 1 of a category\n",
    "    # actual should be a list of 1s and 0s for the actual target category\n",
    "    # thresh should be a float between 0 and 1\n",
    "    # Returns the accuracy at the given threshold\n",
    "    preds = np.array(preds) >= thresh\n",
    "    actual = np.array(actual) == 1\n",
    "    actual = (actual == 1)\n",
    "    acc = np.count_nonzero(preds == actual)/len(actual)\n",
    "    return acc\n",
    "\n",
    "def precision(actual, preds, thresh):\n",
    "    preds = (np.array(preds) >= thresh)\n",
    "    actual = (np.array(actual) == 1)\n",
    "    tp = np.count_nonzero(preds & actual)\n",
    "    fp = np.count_nonzero(preds & ~actual)\n",
    "    prec = tp/(tp+fp)\n",
    "    return prec\n",
    "\n",
    "def f1_score(actual, preds, thresh):\n",
    "    preds = (np.array(preds) >= thresh)\n",
    "    actual = (np.array(actual) == 1)\n",
    "    tp = np.count_nonzero(preds & actual)\n",
    "    fp = np.count_nonzero(preds & ~actual)\n",
    "    fn = np.count_nonzero(~preds & actual)\n",
    "    rec = tp/(tp+fn)\n",
    "    prec = tp/(tp+fp)\n",
    "    f1 = (2 * rec * prec)/(rec + prec)\n",
    "    return(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5939f2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"DAYS_EMPLOYED\"].replace(365243, np.nan, inplace=True)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\Panda\\AppData\\Local\\Temp\\ipykernel_9864\\2390303358.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col + \"_MISSING\"] = df[col].isna().astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining NaNs: 0\n",
      "Final shape: (30000, 244)\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 1. LOAD DATA\n",
    "# ============================\n",
    "df = pd.read_csv(\"application_train.csv\")\n",
    "df = df.sample(n=30000, random_state=42)\n",
    "\n",
    "# ============================\n",
    "# 2. FIX SPECIAL VALUES\n",
    "# ============================\n",
    "\n",
    "# DAYS_EMPLOYED = 365243 means “no employment record”\n",
    "df[\"DAYS_EMPLOYED\"].replace(365243, np.nan, inplace=True)\n",
    "\n",
    "# MAKE MISSINGNESS INDICATORS (best-practice for this dataset)\n",
    "for col in df.columns:\n",
    "    df[col + \"_MISSING\"] = df[col].isna().astype(int)\n",
    "\n",
    "# ============================\n",
    "# 3. IDENTIFY CATEGORICAL COLS\n",
    "# ============================\n",
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# ============================\n",
    "# 4. COERCE NUMERIC-LIKE COLS\n",
    "# ============================\n",
    "numeric_like_cols = df.columns.difference(categorical_cols)\n",
    "\n",
    "df[numeric_like_cols] = df[numeric_like_cols].apply(\n",
    "    lambda col: pd.to_numeric(col, errors=\"coerce\")\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 5. SET UP NUMERIC & CATEGORICAL COL LISTS\n",
    "# ============================\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "numeric_cols = numeric_cols.drop(\"TARGET\")  # do NOT impute target\n",
    "\n",
    "# ============================\n",
    "# 6. IMPUTE NUMERICS (median) & CATEGORICALS (mode)\n",
    "# ============================\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "df[numeric_cols] = num_imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "df[categorical_cols] = cat_imputer.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Confirm no NaNs\n",
    "print(\"Remaining NaNs:\", df.isna().sum().sum())\n",
    "\n",
    "# ============================\n",
    "# 7. ONE-HOT ENCODE CATEGORICAL FIELDS\n",
    "# ============================\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# ============================\n",
    "# 8. CORRELATION BASED FILTERING\n",
    "# ============================\n",
    "correlations = df_encoded.corr()[\"TARGET\"]\n",
    "low_corr_cols = correlations[abs(correlations) < 0.01].index.tolist()\n",
    "\n",
    "# DO NOT drop TARGET even if correlation calculation returns it\n",
    "low_corr_cols = [col for col in low_corr_cols if col != \"TARGET\"]\n",
    "\n",
    "df_filtered = df_encoded.drop(columns=low_corr_cols, errors='ignore')\n",
    "\n",
    "print(\"Final shape:\", df_filtered.shape)\n",
    "\n",
    "# ============================\n",
    "# 9. READY FOR MODELING\n",
    "# ============================\n",
    "X = df_filtered.drop(\"TARGET\", axis=1)\n",
    "y = df_filtered[\"TARGET\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318a9a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Panda\\OneDrive\\Desktop\\Data 403 - Project 2\\DATA403-Project-2\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 10000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=10000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Precision: 0.5\n",
      "SVM Precision: 1.0\n",
      "LDA Precision: 0.49693251533742333\n",
      "LR Recall: 0.000407000407000407\n",
      "SVM Recall: 0.000407000407000407\n",
      "LDA Recall: 0.03296703296703297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "model1 = LogisticRegression(max_iter=10000)\n",
    "model2 = svm.SVC(probability=True)\n",
    "model3 = LinearDiscriminantAnalysis()\n",
    "\n",
    "model1.fit(X, y)\n",
    "model2.fit(X, y)\n",
    "model3.fit(X, y)\n",
    "\n",
    "pred1 = model1.predict(X)\n",
    "pred2 = model2.predict(X)\n",
    "pred3 = model3.predict(X)\n",
    "\n",
    "print(\"LR Precision:\", precision_score(y, pred1))\n",
    "print(\"SVM Precision:\", precision_score(y, pred2))\n",
    "print(\"LDA Precision:\", precision_score(y, pred3))\n",
    "\n",
    "print(\"LR Recall:\", recall_score(y, pred1))\n",
    "print(\"SVM Recall:\", recall_score(y, pred2))\n",
    "print(\"LDA Recall:\", recall_score(y, pred3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4d04b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78b1764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'LIVINGAPARTMENTS_MEDI', NONLIVINGAPARTMENTS_MEDI'\n",
    "#not sure if we should drop these? possible proxies for age??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e61694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "574a0a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.639729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.500679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.757488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model   ROC-AUC\n",
       "0  Logistic Regression  0.639729\n",
       "1                  SVM  0.500679\n",
       "2                  LDA  0.757488"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# 10. ROC-AUC EVALUATION\n",
    "# ============================\n",
    "prob_predictions = {\n",
    "    \"Logistic Regression\": model1.predict_proba(X)[:, 1],\n",
    "    \"SVM\": model2.predict_proba(X)[:, 1],\n",
    "    \"LDA\": model3.predict_proba(X)[:, 1],\n",
    "}\n",
    "\n",
    "roc_auc_rows = []\n",
    "for name, probs in prob_predictions.items():\n",
    "    roc_auc_rows.append({\n",
    "        \"Model\": name,\n",
    "        \"ROC-AUC\": roc_auc(y, probs),\n",
    "    })\n",
    "\n",
    "pd.DataFrame(roc_auc_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b585c564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy (custom)</th>\n",
       "      <th>Precision (custom)</th>\n",
       "      <th>F1 (custom)</th>\n",
       "      <th>Precision (sklearn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.918100</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.918133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.918067</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.061832</td>\n",
       "      <td>0.496933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy (custom)  Precision (custom)  F1 (custom)  \\\n",
       "0  Logistic Regression           0.918100            0.500000     0.000813   \n",
       "1                  SVM           0.918133            1.000000     0.000814   \n",
       "2                  LDA           0.918067            0.496933     0.061832   \n",
       "\n",
       "   Precision (sklearn)  \n",
       "0             0.500000  \n",
       "1             1.000000  \n",
       "2             0.496933  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# 11. ADDITIONAL METRICS (ACCURACY, PRECISION, F1)\n",
    "# ============================\n",
    "threshold = 0.5\n",
    "\n",
    "metric_rows = []\n",
    "for name, probs in prob_predictions.items():\n",
    "    preds_binary = (probs >= threshold).astype(int)\n",
    "    metric_rows.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy (custom)\": accuracy(y, probs, threshold),\n",
    "        \"Precision (custom)\": precision(y, probs, threshold),\n",
    "        \"F1 (custom)\": f1_score(y, probs, threshold),\n",
    "        \"Precision (sklearn)\": precision_score(y, preds_binary),\n",
    "    })\n",
    "\n",
    "pd.DataFrame(metric_rows)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
