{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0447df",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Datasets/bureau.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mn\u001b[39;00m\n\u001b[32m      4\u001b[39m application_train_df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mrory_work/application_train.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m bureau_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDatasets/bureau.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m prev_app_df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mDatasets/previous_application.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Datasets/bureau.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as n\n",
    "\n",
    "application_train_df = pd.read_csv('rory_work/application_train.csv')\n",
    "bureau_df = pd.read_csv('Datasets/bureau.csv')\n",
    "prev_app_df = pd.read_csv('Datasets/previous_application.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf0d8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  application_train_df[\"DAYS_EMPLOYED\"].replace(365243, np.nan, inplace=True)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_17572\\255203758.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining NaNs: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "application_train_df[\"DAYS_EMPLOYED\"].replace(365243, np.nan, inplace=True)\n",
    "\n",
    "\n",
    "for col in application_train_df.columns:\n",
    "    application_train_df[col + \"_MISSING\"] = application_train_df[col].isna().astype(int)\n",
    "\n",
    "categorical_cols = application_train_df.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "numeric_like_cols = application_train_df.columns.difference(categorical_cols)\n",
    "\n",
    "application_train_df[numeric_like_cols] = application_train_df[numeric_like_cols].apply(\n",
    "    lambda col: pd.to_numeric(col, errors=\"coerce\")\n",
    ")\n",
    "\n",
    "\n",
    "numeric_cols = application_train_df.select_dtypes(include=[np.number]).columns\n",
    "numeric_cols = numeric_cols.drop(\"TARGET\")  \n",
    "\n",
    "\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "application_train_df[numeric_cols] = num_imputer.fit_transform(application_train_df[numeric_cols])\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "application_train_df[categorical_cols] = cat_imputer.fit_transform(application_train_df[categorical_cols])\n",
    "\n",
    "# Confirm no NaNs\n",
    "print(\"Remaining NaNs:\", application_train_df.isna().sum().sum())\n",
    "\n",
    "\n",
    "df_encoded = pd.get_dummies(application_train_df, drop_first=True)\n",
    "\n",
    "\n",
    "correlations = df_encoded.corr()[\"TARGET\"]\n",
    "low_corr_cols = correlations[abs(correlations) < 0.01].index.tolist()\n",
    "\n",
    "\n",
    "low_corr_cols = [col for col in low_corr_cols if col != \"TARGET\"]\n",
    "\n",
    "df_filtered = df_encoded.drop(columns=low_corr_cols, errors='ignore')\n",
    "\n",
    "print(\"Final shape:\", df_filtered.shape)\n",
    "\n",
    "\n",
    "X = df_filtered.drop(\"TARGET\", axis=1)\n",
    "y = df_filtered[\"TARGET\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3994a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "application_bureau_df = pd.merge(application_train_df, bureau_df, on = \"SK_ID_CURR\")\n",
    "total_overdue = application_bureau_df.groupby(\"SK_ID_CURR\")[\"AMT_CREDIT_SUM_OVERDUE\"].sum()\n",
    "total_debt = application_bureau_df.groupby(\"SK_ID_CURR\")[\"AMT_CREDIT_SUM_DEBT\"].sum()\n",
    "times_prolonged = application_bureau_df.groupby(\"SK_ID_CURR\")[\"CNT_CREDIT_PROLONG\"].sum()\n",
    "days_overdue = application_bureau_df.groupby(\"SK_ID_CURR\")[\"CREDIT_DAY_OVERDUE\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb246e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_merged_df = application_train_df.merge(total_overdue, on='SK_ID_CURR', how='left')\n",
    "application_train_merged_df = application_train_merged_df.merge(total_debt, on='SK_ID_CURR', how='left')\n",
    "application_train_merged_df = application_train_merged_df.merge(times_prolonged, on='SK_ID_CURR', how='left')\n",
    "application_train_merged_df = application_train_merged_df.merge(days_overdue, on = \"SK_ID_CURR\", how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20242d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_merged_df['AMT_CREDIT_SUM_OVERDUE'] = application_train_merged_df['AMT_CREDIT_SUM_OVERDUE'].fillna(0)\n",
    "application_train_merged_df['AMT_CREDIT_SUM_DEBT'] = application_train_merged_df['AMT_CREDIT_SUM_DEBT'].fillna(0)\n",
    "application_train_merged_df['CNT_CREDIT_PROLONG'] = application_train_merged_df['CNT_CREDIT_PROLONG'].fillna(0)\n",
    "application_train_merged_df['CREDIT_DAY_OVERDUE'] = application_train_merged_df['CREDIT_DAY_OVERDUE'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7148294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nerdc\\AppData\\Local\\Temp\\ipykernel_39080\\1380318554.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prev_app_ct[\"PREV_APPS\"] = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREV_APPS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100005</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456251</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456252</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456253</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456254</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456255</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338857 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PREV_APPS\n",
       "SK_ID_CURR           \n",
       "100001              1\n",
       "100002              1\n",
       "100003              3\n",
       "100004              1\n",
       "100005              2\n",
       "...               ...\n",
       "456251              1\n",
       "456252              1\n",
       "456253              2\n",
       "456254              2\n",
       "456255              8\n",
       "\n",
       "[338857 rows x 1 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_app_ct = prev_app_df[[\"SK_ID_CURR\"]]\n",
    "prev_app_ct[\"PREV_APPS\"] = 0\n",
    "prev_app_ct = prev_app_ct.groupby(\"SK_ID_CURR\").count()\n",
    "prev_app_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa0eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nerdc\\AppData\\Local\\Temp\\ipykernel_39080\\326452719.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prev_app_approved[\"NUM_APPROVED\"] = np.where(prev_app_approved[\"NAME_CONTRACT_STATUS\"] == \"Approved\", 1, 0)\n"
     ]
    }
   ],
   "source": [
    "prev_app_approved = prev_app_df[[\"SK_ID_CURR\", \"NAME_CONTRACT_STATUS\"]]\n",
    "prev_app_approved[\"NUM_APPROVED\"] = np.where(prev_app_approved[\"NAME_CONTRACT_STATUS\"] == \"Approved\", 1, 0)\n",
    "prev_app_approved = prev_app_approved.groupby(\"SK_ID_CURR\").sum().reset_index()\n",
    "prev_app_approved = prev_app_approved[[\"SK_ID_CURR\", \"NUM_APPROVED\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10993616",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_ct = prev_app_ct.merge(prev_app_approved, on=\"SK_ID_CURR\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaedf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_merged_df = application_train_merged_df.merge(prev_app_ct, on=\"SK_ID_CURR\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "cols_to_standardize = ['AMT_CREDIT_SUM_OVERDUE', 'AMT_CREDIT_SUM_DEBT', 'CNT_CREDIT_PROLONG', 'CREDIT_DAY_OVERDUE', 'PREV_APPS', 'NUM_APPROVED']\n",
    "\n",
    "application_train_merged_df[cols_to_standardize] = scaler.fit_transform(application_train_merged_df[cols_to_standardize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa51e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_train_merged_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a3ef1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Cash loans'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Variable Selection\u001b[39;00m\n\u001b[32m      2\u001b[39m pd.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.max_rows\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1000\u001b[39m)  \n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m correlation_matrix = \u001b[43mapplication_train_merged_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m target_column_name = \u001b[33m'\u001b[39m\u001b[33mTARGET\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      6\u001b[39m target_correlations = correlation_matrix[target_column_name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerdc\\.venvs\\data403\\Lib\\site-packages\\pandas\\core\\frame.py:11076\u001b[39m, in \u001b[36mDataFrame.corr\u001b[39m\u001b[34m(self, method, min_periods, numeric_only)\u001b[39m\n\u001b[32m  11074\u001b[39m cols = data.columns\n\u001b[32m  11075\u001b[39m idx = cols.copy()\n\u001b[32m> \u001b[39m\u001b[32m11076\u001b[39m mat = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m  11078\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mpearson\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m  11079\u001b[39m     correl = libalgos.nancorr(mat, minp=min_periods)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerdc\\.venvs\\data403\\Lib\\site-packages\\pandas\\core\\frame.py:2002\u001b[39m, in \u001b[36mDataFrame.to_numpy\u001b[39m\u001b[34m(self, dtype, copy, na_value)\u001b[39m\n\u001b[32m   2000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2001\u001b[39m     dtype = np.dtype(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2002\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2003\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[32m   2004\u001b[39m     result = np.asarray(result, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerdc\\.venvs\\data403\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1713\u001b[39m, in \u001b[36mBlockManager.as_array\u001b[39m\u001b[34m(self, dtype, copy, na_value)\u001b[39m\n\u001b[32m   1711\u001b[39m         arr.flags.writeable = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1712\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1713\u001b[39m     arr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1714\u001b[39m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[32m   1715\u001b[39m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[32m   1717\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerdc\\.venvs\\data403\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1772\u001b[39m, in \u001b[36mBlockManager._interleave\u001b[39m\u001b[34m(self, dtype, na_value)\u001b[39m\n\u001b[32m   1770\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1771\u001b[39m         arr = blk.get_values(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m1772\u001b[39m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m = arr\n\u001b[32m   1773\u001b[39m     itemmask[rl.indexer] = \u001b[32m1\u001b[39m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask.all():\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Cash loans'"
     ]
    }
   ],
   "source": [
    "# Variable Selection\n",
    "pd.set_option('display.max_rows', 1000)  \n",
    "\n",
    "correlation_matrix = application_train_merged_df.corr()\n",
    "target_column_name = 'TARGET'\n",
    "target_correlations = correlation_matrix[target_column_name]\n",
    "print(f\"\\nCorrelations with '{target_column_name}':\")\n",
    "# print(target_correlations)\n",
    "\n",
    "\n",
    "sorted_target_correlations = target_correlations.sort_values(ascending=False)\n",
    "print(f\"\\nSorted correlations with '{target_column_name}':\")\n",
    "print(sorted_target_correlations)\n",
    "\n",
    "print(application_train_merged_df['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f50de39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with less than 0.01 correlation to 'TARGET':\n",
      "['CNT_FAM_MEMBERS', 'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'REG_REGION_NOT_WORK_REGION', 'REG_REGION_NOT_LIVE_REGION', 'FLAG_DOCUMENT_2', 'NAME_FAMILY_STATUS', 'CREDIT_DAY_OVERDUE', 'FLAG_DOCUMENT_21', 'LIVE_REGION_NOT_WORK_REGION', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_CREDIT_SUM_DEBT', 'CNT_CREDIT_PROLONG', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'FLAG_MOBIL', 'FONDKAPREMONT_MODE', 'FLAG_CONT_MOBILE', 'FLAG_DOCUMENT_20', 'WEEKDAY_APPR_PROCESS_START', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_7', 'NONLIVINGAPARTMENTS_MODE', 'FLAG_EMAIL', 'AMT_REQ_CREDIT_BUREAU_QRT', 'SK_ID_CURR', 'FLAG_DOCUMENT_4', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAPARTMENTS_AVG', 'FLAG_DOCUMENT_17', 'AMT_INCOME_TOTAL', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_9', 'NAME_TYPE_SUITE', 'FLAG_OWN_REALTY', 'FLAG_DOCUMENT_15', 'OCCUPATION_TYPE', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_8', 'YEARS_BEGINEXPLUATATION_MODE', 'FLAG_DOCUMENT_14', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BEGINEXPLUATATION_MEDI']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>AMT_CREDIT_SUM_OVERDUE</th>\n",
       "      <th>AMT_CREDIT_SUM_DEBT</th>\n",
       "      <th>CNT_CREDIT_PROLONG</th>\n",
       "      <th>CREDIT_DAY_OVERDUE</th>\n",
       "      <th>PREV_APPS</th>\n",
       "      <th>NUM_APPROVED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6206.0</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6.206000e+03</td>\n",
       "      <td>6.206000e+03</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6206.000000</td>\n",
       "      <td>6206.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>277628.523526</td>\n",
       "      <td>0.064776</td>\n",
       "      <td>0.103287</td>\n",
       "      <td>0.495972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.701096</td>\n",
       "      <td>0.606671</td>\n",
       "      <td>2.196898e+05</td>\n",
       "      <td>6.868752e+05</td>\n",
       "      <td>31460.237432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041412</td>\n",
       "      <td>0.371092</td>\n",
       "      <td>0.269256</td>\n",
       "      <td>1.843539</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.432140</td>\n",
       "      <td>0.092621</td>\n",
       "      <td>-0.025131</td>\n",
       "      <td>0.030644</td>\n",
       "      <td>0.039844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>103598.458034</td>\n",
       "      <td>0.246150</td>\n",
       "      <td>0.304358</td>\n",
       "      <td>0.500024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457815</td>\n",
       "      <td>0.773960</td>\n",
       "      <td>1.366682e+05</td>\n",
       "      <td>4.460252e+05</td>\n",
       "      <td>16008.211503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214073</td>\n",
       "      <td>1.049797</td>\n",
       "      <td>0.609232</td>\n",
       "      <td>1.754519</td>\n",
       "      <td>0.530368</td>\n",
       "      <td>1.480172</td>\n",
       "      <td>1.269631</td>\n",
       "      <td>0.592071</td>\n",
       "      <td>0.976472</td>\n",
       "      <td>1.006781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100083.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.375000e+04</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>3411.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012514</td>\n",
       "      <td>-0.681064</td>\n",
       "      <td>-0.151294</td>\n",
       "      <td>-0.049444</td>\n",
       "      <td>-0.930093</td>\n",
       "      <td>-1.432948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>187172.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.350000e+05</td>\n",
       "      <td>3.141000e+05</td>\n",
       "      <td>19803.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012514</td>\n",
       "      <td>-0.348799</td>\n",
       "      <td>-0.151294</td>\n",
       "      <td>-0.049444</td>\n",
       "      <td>-0.688957</td>\n",
       "      <td>-0.491587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>276788.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.890000e+05</td>\n",
       "      <td>5.772802e+05</td>\n",
       "      <td>29299.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012514</td>\n",
       "      <td>-0.093099</td>\n",
       "      <td>-0.151294</td>\n",
       "      <td>-0.049444</td>\n",
       "      <td>-0.206684</td>\n",
       "      <td>-0.020906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>369441.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.700000e+05</td>\n",
       "      <td>9.423000e+05</td>\n",
       "      <td>40320.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.012514</td>\n",
       "      <td>0.564151</td>\n",
       "      <td>-0.151294</td>\n",
       "      <td>-0.049444</td>\n",
       "      <td>0.516724</td>\n",
       "      <td>0.449774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>456226.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.500000e+06</td>\n",
       "      <td>4.050000e+06</td>\n",
       "      <td>171040.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>27.509062</td>\n",
       "      <td>28.887978</td>\n",
       "      <td>26.022864</td>\n",
       "      <td>30.807434</td>\n",
       "      <td>11.367850</td>\n",
       "      <td>7.980660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SK_ID_CURR       TARGET  NAME_CONTRACT_TYPE  CODE_GENDER  \\\n",
       "count    6206.000000  6206.000000         6206.000000  6206.000000   \n",
       "mean   277628.523526     0.064776            0.103287     0.495972   \n",
       "std    103598.458034     0.246150            0.304358     0.500024   \n",
       "min    100083.000000     0.000000            0.000000     0.000000   \n",
       "25%    187172.750000     0.000000            0.000000     0.000000   \n",
       "50%    276788.000000     0.000000            0.000000     0.000000   \n",
       "75%    369441.250000     0.000000            0.000000     1.000000   \n",
       "max    456226.000000     1.000000            1.000000     1.000000   \n",
       "\n",
       "       FLAG_OWN_CAR  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
       "count        6206.0      6206.000000   6206.000000      6.206000e+03   \n",
       "mean            1.0         0.701096      0.606671      2.196898e+05   \n",
       "std             0.0         0.457815      0.773960      1.366682e+05   \n",
       "min             1.0         0.000000      0.000000      3.375000e+04   \n",
       "25%             1.0         0.000000      0.000000      1.350000e+05   \n",
       "50%             1.0         1.000000      0.000000      1.890000e+05   \n",
       "75%             1.0         1.000000      1.000000      2.700000e+05   \n",
       "max             1.0         1.000000      5.000000      4.500000e+06   \n",
       "\n",
       "         AMT_CREDIT    AMT_ANNUITY  ...  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "count  6.206000e+03    6206.000000  ...                 6206.000000   \n",
       "mean   6.868752e+05   31460.237432  ...                    0.041412   \n",
       "std    4.460252e+05   16008.211503  ...                    0.214073   \n",
       "min    4.500000e+04    3411.000000  ...                    0.000000   \n",
       "25%    3.141000e+05   19803.375000  ...                    0.000000   \n",
       "50%    5.772802e+05   29299.500000  ...                    0.000000   \n",
       "75%    9.423000e+05   40320.000000  ...                    0.000000   \n",
       "max    4.050000e+06  171040.500000  ...                    4.000000   \n",
       "\n",
       "       AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "count                6206.000000                6206.000000   \n",
       "mean                    0.371092                   0.269256   \n",
       "std                     1.049797                   0.609232   \n",
       "min                     0.000000                   0.000000   \n",
       "25%                     0.000000                   0.000000   \n",
       "50%                     0.000000                   0.000000   \n",
       "75%                     0.000000                   0.000000   \n",
       "max                    16.000000                   8.000000   \n",
       "\n",
       "       AMT_REQ_CREDIT_BUREAU_YEAR  AMT_CREDIT_SUM_OVERDUE  \\\n",
       "count                 6206.000000             6206.000000   \n",
       "mean                     1.843539                0.005001   \n",
       "std                      1.754519                0.530368   \n",
       "min                      0.000000               -0.012514   \n",
       "25%                      1.000000               -0.012514   \n",
       "50%                      1.000000               -0.012514   \n",
       "75%                      3.000000               -0.012514   \n",
       "max                     17.000000               27.509062   \n",
       "\n",
       "       AMT_CREDIT_SUM_DEBT  CNT_CREDIT_PROLONG  CREDIT_DAY_OVERDUE  \\\n",
       "count          6206.000000         6206.000000         6206.000000   \n",
       "mean              0.432140            0.092621           -0.025131   \n",
       "std               1.480172            1.269631            0.592071   \n",
       "min              -0.681064           -0.151294           -0.049444   \n",
       "25%              -0.348799           -0.151294           -0.049444   \n",
       "50%              -0.093099           -0.151294           -0.049444   \n",
       "75%               0.564151           -0.151294           -0.049444   \n",
       "max              28.887978           26.022864           30.807434   \n",
       "\n",
       "         PREV_APPS  NUM_APPROVED  \n",
       "count  6206.000000   6206.000000  \n",
       "mean      0.030644      0.039844  \n",
       "std       0.976472      1.006781  \n",
       "min      -0.930093     -1.432948  \n",
       "25%      -0.688957     -0.491587  \n",
       "50%      -0.206684     -0.020906  \n",
       "75%       0.516724      0.449774  \n",
       "max      11.367850      7.980660  \n",
       "\n",
       "[8 rows x 128 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Columns with less that 0.01 correlation to target\n",
    "\n",
    "low_correlation_columns = sorted_target_correlations[abs(sorted_target_correlations) < 0.01].index.tolist()\n",
    "print(f\"\\nColumns with less than 0.01 correlation to '{target_column_name}':\")\n",
    "print(low_correlation_columns)\n",
    "\n",
    "application_train_merged_df = application_train_merged_df.dropna()\n",
    "\n",
    "df_correlation = application_train_merged_df.drop(columns=low_correlation_columns)\n",
    "\n",
    "df_correlation = df_correlatio.f['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0891d17f",
   "metadata": {},
   "source": [
    "Split code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d58b273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_train_merged_df.shape[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
