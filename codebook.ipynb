{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "116b73e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "application_train_df = pd.read_csv('Datasets/application_train.csv')\n",
    "bureau_df = pd.read_csv('Datasets/bureau.csv')\n",
    "prev_app_df = pd.read_csv('Datasets/previous_application.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baf0d8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         1\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "307506    0\n",
      "307507    0\n",
      "307508    0\n",
      "307509    1\n",
      "307510    0\n",
      "Name: TARGET, Length: 307511, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "application_train_df['FLAG_OWN_CAR'] = application_train_df['FLAG_OWN_CAR'].map({'Y': 1, 'N': 0})\n",
    "application_train_df['FLAG_OWN_REALTY'] = application_train_df['FLAG_OWN_REALTY'].map({'Y': 1, 'N': 0})\n",
    "application_train_df['NAME_CONTRACT_TYPE'] = application_train_df['NAME_CONTRACT_TYPE'].map({'Cash loans': 0, 'Revolving loans': 1})\n",
    "application_train_df['CODE_GENDER'] = application_train_df['CODE_GENDER'].map({'M': 0, 'F': 1, 'XNA': 2})\n",
    "application_train_df['NAME_TYPE_SUITE'] = application_train_df['NAME_TYPE_SUITE'].map({'Unaccompanied': 0, 'Family': 1, 'Spouse, partner': 2,\n",
    "                                                   'Children': 3, 'Other_A': 4, 'Other_B': 5, np.nan: 6})\n",
    "application_train_df['NAME_INCOME_TYPE'] = application_train_df['NAME_INCOME_TYPE'].map({'Working': 0, 'State servant': 1, 'Commercial associate': 2,\n",
    "                                                     'Pensioner': 3, 'Unemployed': 4, 'Student': 5, 'Businessman': 6, 'Maternity leave': 7})\n",
    "application_train_df['NAME_EDUCATION_TYPE'] = application_train_df['NAME_EDUCATION_TYPE'].map({'Secondary / secondary special': 0, 'Higher education': 1,\n",
    "                                                           'Incomplete higher': 2, 'Lower secondary': 3, 'Academic degree': 4})\n",
    "application_train_df['NAME_FAMILY_STATUS'] = application_train_df['NAME_FAMILY_STATUS'].map({'Married': 0, 'Single / not married': 1, 'Civil marriage': 2,\n",
    "                                                         'Separated': 3, 'Widow': 4})             \n",
    "application_train_df['NAME_HOUSING_TYPE'] = application_train_df['NAME_HOUSING_TYPE'].map({'House / apartment': 0, 'With parents': 1, 'Municipal apartment': 2,\n",
    "                                                       'Rented apartment': 3, 'Office apartment': 4, 'Co-op apartment': 5})\n",
    "application_train_df['OCCUPATION_TYPE'] = application_train_df['OCCUPATION_TYPE'].map({'Laborers': 0, 'Core staff': 1, 'Accountants': 2, 'Managers': 3, 'Drivers': 4,\n",
    "                                                   'Sales staff': 5, 'Cleaning staff': 6, 'Cooking staff': 7, 'Private service staff': 8, 'Medicine staff': 9})                                                                                                     \n",
    "application_train_df['WEEKDAY_APPR_PROCESS_START'] = application_train_df['WEEKDAY_APPR_PROCESS_START'].map({'MONDAY': 0, 'TUESDAY': 1, 'WEDNESDAY': 2,\n",
    "                                                                       'THURSDAY': 3, 'FRIDAY': 4, 'SATURDAY': 5, 'SUNDAY': 6})\n",
    "application_train_df['ORGANIZATION_TYPE'] = application_train_df['ORGANIZATION_TYPE'].astype('category').cat.codes\n",
    "application_train_df['FONDKAPREMONT_MODE'] = application_train_df['FONDKAPREMONT_MODE'].map({'reg oper account': 0, 'org spec account': 1,\n",
    "                                                         'not specified': 2, 'org oper account': 3})\n",
    "application_train_df['HOUSETYPE_MODE'] = application_train_df['HOUSETYPE_MODE'].map({'block of flats': 0, 'specific housing': 1,\n",
    "                                                 'terraced house': 2, 'specific housing block': 3, np.nan: 4})\n",
    "application_train_df['WALLSMATERIAL_MODE'] = application_train_df['WALLSMATERIAL_MODE'].map({'Stone, brick': 0, 'Wooden': 1, 'Panel': 2,\n",
    "                                                         'Block': 3, 'Mixed': 4, 'Monolithic': 5, np.nan: 6})\n",
    "application_train_df['EMERGENCYSTATE_MODE'] = application_train_df['EMERGENCYSTATE_MODE'].map({'No': 0, 'Yes': 1, np.nan: 2})\n",
    "print(application_train_df['TARGET'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e3994a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_bureau_df = pd.merge(application_train_df, bureau_df, on = \"SK_ID_CURR\")\n",
    "total_overdue = application_bureau_df.groupby(\"SK_ID_CURR\")[\"AMT_CREDIT_SUM_OVERDUE\"].sum()\n",
    "total_debt = application_bureau_df.groupby(\"SK_ID_CURR\")[\"AMT_CREDIT_SUM_DEBT\"].sum()\n",
    "times_prolonged = application_bureau_df.groupby(\"SK_ID_CURR\")[\"CNT_CREDIT_PROLONG\"].sum()\n",
    "days_overdue = application_bureau_df.groupby(\"SK_ID_CURR\")[\"CREDIT_DAY_OVERDUE\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb246e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_merged_df = application_train_df.merge(total_overdue, on='SK_ID_CURR', how='left')\n",
    "application_train_merged_df = application_train_merged_df.merge(total_debt, on='SK_ID_CURR', how='left')\n",
    "application_train_merged_df = application_train_merged_df.merge(times_prolonged, on='SK_ID_CURR', how='left')\n",
    "application_train_merged_df = application_train_merged_df.merge(days_overdue, on = \"SK_ID_CURR\", how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20242d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_merged_df['AMT_CREDIT_SUM_OVERDUE'] = application_train_merged_df['AMT_CREDIT_SUM_OVERDUE'].fillna(0)\n",
    "application_train_merged_df['AMT_CREDIT_SUM_DEBT'] = application_train_merged_df['AMT_CREDIT_SUM_DEBT'].fillna(0)\n",
    "application_train_merged_df['CNT_CREDIT_PROLONG'] = application_train_merged_df['CNT_CREDIT_PROLONG'].fillna(0)\n",
    "application_train_merged_df['CREDIT_DAY_OVERDUE'] = application_train_merged_df['CREDIT_DAY_OVERDUE'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392b4ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      3\u001b[39m scaler = StandardScaler()\n\u001b[32m      4\u001b[39m cols_to_standardize = [\u001b[33m'\u001b[39m\u001b[33mAMT_CREDIT_SUM_OVERDUE\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mAMT_CREDIT_SUM_DEBT\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCNT_CREDIT_PROLONG\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCREDIT_DAY_OVERDUE\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "cols_to_standardize = ['AMT_CREDIT_SUM_OVERDUE', 'AMT_CREDIT_SUM_DEBT', 'CNT_CREDIT_PROLONG', 'CREDIT_DAY_OVERDUE']\n",
    "\n",
    "application_train_merged_df[cols_to_standardize] = scaler.fit_transform(application_train_merged_df[cols_to_standardize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc9ead0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#%pip install scikit-learn\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(sklearn.__version__)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130be1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_ct = prev_app_df[[\"SK_ID_CURR\"]]\n",
    "prev_app_ct[\"PREV_APPS\"] = 0\n",
    "prev_app_ct = prev_app_ct.groupby(\"SK_ID_CURR\").count()\n",
    "prev_app_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2637661",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_approved = prev_app_df[[\"SK_ID_CURR\", \"NAME_CONTRACT_STATUS\"]]\n",
    "prev_app_approved[\"NUM_APPROVED\"] = np.where(prev_app_approved[\"NAME_CONTRACT_STATUS\"] == \"Approved\", 1, 0)\n",
    "prev_app_approved = prev_app_approved.groupby(\"SK_ID_CURR\").sum().reset_index()\n",
    "prev_app_approved = prev_app_approved[[\"SK_ID_CURR\", \"NUM_APPROVED\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa7b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_ct = prev_app_ct.merge(prev_app_approved, on=\"SK_ID_CURR\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f60dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_merged_df = application_train_merged_df.merge(prev_app_ct, on=\"SK_ID_CURR\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ec5381",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'application_train_merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m pd.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.max_rows\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1000\u001b[39m)  \n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m correlation_matrix = \u001b[43mapplication_train_merged_df\u001b[49m.corr()\n\u001b[32m      4\u001b[39m target_column_name = \u001b[33m'\u001b[39m\u001b[33mTARGET\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m target_correlations = correlation_matrix[target_column_name]\n",
      "\u001b[31mNameError\u001b[39m: name 'application_train_merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 1000)  \n",
    "\n",
    "correlation_matrix = application_train_merged_df.corr()\n",
    "target_column_name = 'TARGET'\n",
    "target_correlations = correlation_matrix[target_column_name]\n",
    "print(f\"\\nCorrelations with '{target_column_name}':\")\n",
    "# print(target_correlations)\n",
    "\n",
    "\n",
    "sorted_target_correlations = target_correlations.sort_values(ascending=False)\n",
    "print(f\"\\nSorted correlations with '{target_column_name}':\")\n",
    "print(sorted_target_correlations)\n",
    "\n",
    "print(application_train_merged_df['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44de44a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_target_correlations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m##Columns with less that 0.01 correlation to target\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m low_correlation_columns = \u001b[43msorted_target_correlations\u001b[49m[\u001b[38;5;28mabs\u001b[39m(sorted_target_correlations) < \u001b[32m0.01\u001b[39m].index.tolist()\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mColumns with less than 0.01 correlation to \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_column_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(low_correlation_columns)\n",
      "\u001b[31mNameError\u001b[39m: name 'sorted_target_correlations' is not defined"
     ]
    }
   ],
   "source": [
    "##Columns with less that 0.01 correlation to target\n",
    "\n",
    "low_correlation_columns = sorted_target_correlations[abs(sorted_target_correlations) < 0.01].index.tolist()\n",
    "print(f\"\\nColumns with less than 0.01 correlation to '{target_column_name}':\")\n",
    "print(low_correlation_columns)\n",
    "\n",
    "application_train_merged_df = application_train_merged_df.dropna()\n",
    "\n",
    "df_correlation = application_train_merged_df.drop(columns=low_correlation_columns)\n",
    "\n",
    "df_correlation = df_correlation.dropna()\n",
    "\n",
    "print(application_train_merged_df['TARGET'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
